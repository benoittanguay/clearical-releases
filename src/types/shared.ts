/**
 * Shared type definitions for TimePortal
 * These types are used across both the Electron main process and React renderer
 */

export interface LinkedJiraIssue {
    key: string;
    summary: string;
    issueType: string;
    status: string;
    projectKey: string;
    projectName: string;
}

export interface WorkAssignment {
    type: 'bucket' | 'jira';
    bucket?: {
        id: string;
        name: string;
        color: string;
    };
    jiraIssue?: LinkedJiraIssue;
}

export interface TimeBucket {
    id: string;
    name: string;
    color: string;
    parentId?: string | null;
    isFolder?: boolean;
    linkedIssue?: LinkedJiraIssue;
}

/**
 * Raw data extracted by Vision Framework (Stage 1)
 * This is the unprocessed OCR and object detection output
 */
export interface VisionFrameworkRawData {
    confidence?: number;
    detectedText?: string[];
    objects?: string[];
    extraction?: any; // StructuredExtraction from Swift Vision Framework
}

/**
 * Complete screenshot analysis result with two-stage architecture
 * Stage 1: Vision Framework extracts raw data
 * Stage 2: LLM generates narrative description from raw data
 */
export interface ScreenshotAnalysisResult {
    // Raw Vision Framework data (Stage 1)
    rawVisionData?: VisionFrameworkRawData;

    // AI-generated narrative description (Stage 2)
    aiDescription?: string;

    // LLM error message if description generation failed
    llmError?: string;

    // Legacy fields for backward compatibility
    description?: string; // Falls back to aiDescription or raw summary
    confidence?: number;
    detectedText?: string[];
    objects?: string[];
    extraction?: any;
}

export interface WindowActivity {
    appName: string;
    windowTitle: string;
    bundleId?: string; // App bundle identifier (e.g., com.google.Chrome) - used for blacklist filtering
    timestamp: number;
    duration: number;
    screenshotPaths?: string[];

    // Legacy fields (deprecated in favor of two-stage architecture)
    screenshotDescriptions?: { [path: string]: string };
    screenshotVisionData?: { [path: string]: VisionFrameworkRawData };

    // NEW: Two-stage architecture fields
    screenshotAnalysis?: { [path: string]: ScreenshotAnalysisResult };
}

/**
 * Transcription segment from Whisper API
 */
export interface TranscriptionSegment {
    id: number;
    start: number;
    end: number;
    text: string;
}

/**
 * Meeting/audio transcription data stored with a time entry
 */
export interface EntryTranscription {
    /** Unique identifier for this transcription */
    transcriptionId: string;
    /** Full transcription text */
    fullText: string;
    /** Timestamped segments */
    segments: TranscriptionSegment[];
    /** Detected language (ISO 639-1 code) */
    language: string;
    /** Audio duration in seconds */
    audioDuration: number;
    /** Word count */
    wordCount: number;
    /** When the transcription was created */
    createdAt: number;
}

/** Status of a pending audio transcription */
export interface PendingTranscription {
    /** Path to the saved audio file */
    audioPath: string;
    /** MIME type of the audio file */
    mimeType: string;
    /** Current status */
    status: 'pending' | 'failed';
    /** Error message if transcription failed */
    error?: string;
    /** Timestamp of last transcription attempt */
    attemptedAt?: number;
}

export interface TimeEntry {
    id: string;
    startTime: number;
    endTime: number;
    duration: number;
    assignment?: WorkAssignment;
    assignmentAutoSelected?: boolean;
    bucketId?: string | null;
    linkedJiraIssue?: LinkedJiraIssue;
    description?: string;
    descriptionAutoGenerated?: boolean;
    detectedTechnologies?: string[];
    detectedActivities?: string[];
    windowActivity?: WindowActivity[];
    screenshotPath?: string;
    tempoAccount?: {
        key: string;
        name: string;
        id: string;
    };
    tempoAccountAutoSelected?: boolean;
    /** Audio transcription from meeting/call recording */
    transcription?: EntryTranscription;
    /** Pending transcription when audio was recorded but transcription failed */
    pendingTranscription?: PendingTranscription;
}
